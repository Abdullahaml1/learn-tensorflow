{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bee3a4",
   "metadata": {},
   "source": [
    "## Tesnor Tutorial [source link](https://www.tensorflow.org/guide/tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206e7b1",
   "metadata": {},
   "source": [
    "## numpy basics [link](https://numpy.org/devdocs/user/absolute_beginners.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fc2605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4aaafa",
   "metadata": {},
   "source": [
    "## Tensor and numpy have same \"axis\" idea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4df6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]]\n",
      "\n",
      "across axis: 0\n",
      "[[12 14 16 18]\n",
      " [20 22 24 26]\n",
      " [28 30 32 34]]\n",
      "\n",
      "across axis: 1\n",
      "[[12 15 18 21]\n",
      " [48 51 54 57]]\n",
      "\n",
      "across axis: 1, 2\n",
      "[ 66 210]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(24).reshape([2, 3, 4]) # axis0 = 2, axis1=3, axis2=axis-1=4\n",
    "print('x=')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "#when we do an operation across a specific axis that meeans -->>>>> REMOVE IT\n",
    "y = np.sum(x, axis=0) # that means remove axis 0 (2, 3, 4) becomes (3, 4)\n",
    "print('across axis: 0')\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "y = np.sum(x, axis=1) # that means remove axis 0 (2, 3, 4) becomes (2, 4)\n",
    "print('across axis: 1')\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "y = np.sum(x, axis=(1,2)) # that means remove axis 0 (2, 3, 4) becomes (2,)\n",
    "print('across axis: 1, 2')\n",
    "print(y)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1893735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ba5856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cb60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convet to numpy array\n",
    "np.array(a)\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53997264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#typical tensor shape\n",
    "#(batach x Height x width x feature)\n",
    "#(axis0, axis1, axis2, axis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a965732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105854e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(c))\n",
    "# Find the index of the largest value\n",
    "print(tf.math.argmax(c))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5ab85",
   "metadata": {},
   "source": [
    "Tensors have shapes.  Some vocabulary:\n",
    "\n",
    "* **Shape**: The length (number of elements) of each of the axes of a tensor.\n",
    "* **Rank**: Number of tensor axes.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
    "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
    "* **Size**: The total number of items in the tensor, the product of the shape vector's elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba4d9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of axes: 4\n",
      "Shape of tensor: (5, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 5\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5):  200\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([5 2 4 5], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor = tf.zeros([5, 2, 4, 5])\n",
    "print(\"Type of every element:\", rank_4_tensor.dtype) # does not return tensor\n",
    "print(\"Number of axes:\", rank_4_tensor.ndim) # does not return tensor --> rank\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape) # does not return tensor\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0]) # does not return tensor\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1]) # does not return tensor\n",
    "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy()) # does not return tensor\n",
    "\n",
    "\n",
    "#### REturn a tensor #######\n",
    "print(tf.rank(rank_4_tensor))\n",
    "print(tf.shape(rank_4_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733fe5b",
   "metadata": {},
   "source": [
    "### Single-axis indexing\n",
    "\n",
    "TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings){:.external}, and the basic rules for NumPy indexing.\n",
    "\n",
    "* indexes start at `0`\n",
    "* negative indices count backwards from the end\n",
    "* colons, `:`, are used for slices: `start:stop:step`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355beb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second column: [2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441cfc3",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e9dfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1], [2], [3]])\n",
    "reshaped = tf.reshape(x, [1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "310def5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "# You can convert this object into a Python list, too\n",
    "print(x.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8865840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before flattening\n",
      "(3, 2, 5)\n",
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "print('before flattening')\n",
    "print(rank_3_tensor.shape)\n",
    "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
    "print(tf.reshape(rank_3_tensor, [-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c52cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [3, -1])) # -1 here is the reset of the shape: 2*5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4f7b5",
   "metadata": {},
   "source": [
    "Swapping axes in `tf.reshape` does not work; you need `tf.transpose` for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf50cd8",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d2e51",
   "metadata": {},
   "source": [
    "Unlike a mathematical op, for example, `broadcast_to` does nothing special to save memory.  Here, you are materializing the tensor.\n",
    "\n",
    "It can get even more complicated.  [This section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html){:.external} of Jake VanderPlas's book _Python Data Science Handbook_ shows more broadcasting tricks (again in NumPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0614b32d",
   "metadata": {},
   "source": [
    "## Ragged Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e0a326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n",
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "# A tensor with not a rectangular shape\n",
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "try:\n",
    "  tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# The shape of a tf.RaggedTensor will contain some axes with unknown lengths:\n",
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0522e46",
   "metadata": {},
   "source": [
    "## String tensors\n",
    "\n",
    "`tf.string` is a `dtype`, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\n",
    "\n",
    "The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. See `tf.strings` for functions to manipulate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02466a7",
   "metadata": {},
   "source": [
    "## Sparse tensors\n",
    "\n",
    "Sometimes, your data is sparse, like a very wide embedding space.  TensorFlow supports `tf.sparse.SparseTensor` and related operations to store sparse data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7fdf964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Sparse tensors store values by index in a memory-efficient manner\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# You can convert sparse tensors to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b0e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
